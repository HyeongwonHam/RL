````markdown
# ðŸ¤– LiDAR-based Maze Exploration with PPO Variants

ì´ í”„ë¡œì íŠ¸ëŠ” **ê°•í™”í•™ìŠµ(Reinforcement Learning)**ì„ ì´ìš©í•˜ì—¬ ì—ì´ì „íŠ¸ê°€ 2D LiDAR ì„¼ì„œ ì •ë³´ë§Œìœ¼ë¡œ ë¯¸ì§€(Unknown)ì˜ ë¯¸ë¡œ í™˜ê²½ì„ íš¨ìœ¨ì ìœ¼ë¡œ íƒìƒ‰í•˜ê³  ì§€ë„ë¥¼ ìž‘ì„±(Mapping)í•˜ë„ë¡ í›ˆë ¨í•˜ëŠ” ì—°êµ¬ìž…ë‹ˆë‹¤.

ê¸°ë³¸ì ì¸ **PPO(Proximal Policy Optimization)** ì•Œê³ ë¦¬ì¦˜ê³¼ ë¶€ë¶„ ê´€ì¸¡ì„±(Partially Observable) ë¬¸ì œë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•œ **ê¸°ì–µ ê¸°ë°˜ ë³€í˜• ëª¨ë¸(History-PPO, Recurrent-PPO, CNN-PPO)**ì„ êµ¬í˜„í•˜ê³  ì„±ëŠ¥ì„ ë¹„êµ ë¶„ì„í–ˆìŠµë‹ˆë‹¤.

---

## ðŸ“Œ ì£¼ìš” íŠ¹ì§• (Key Features)

* **Lightweight Simulation**: Pythonê³¼ NumPy ê¸°ë°˜ì˜ ìžì²´ ê²½ëŸ‰ ì‹œë®¬ë ˆì´í„°ë¥¼ êµ¬ì¶•í•˜ì—¬ ê³ ì† í•™ìŠµ ê°€ëŠ¥.
* **Procedural Maze Generation**: `Recursive Backtracker` ì•Œê³ ë¦¬ì¦˜ê³¼ ê°œë°©ë„(Openness) ê³„ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ ë§¤ ì—í”¼ì†Œë“œë§ˆë‹¤ ìƒˆë¡œìš´ êµ¬ì¡°ì˜ ë¯¸ë¡œ ìƒì„±.
* **Geometric Ray-casting**: ë¬¼ë¦¬ ì—”ì§„ ì—†ì´ ê¸°í•˜í•™ì  ì—°ì‚°ë§Œìœ¼ë¡œ ì •ë°€í•œ 2D LiDAR ì„¼ì„œ ëª¨ë¸ë§.
* **Multi-Model Comparison**: Baseline(PPO)ë¶€í„° ê³ ê¸‰ ëª¨ë¸(C-PPO, R-PPO)ê¹Œì§€ 4ê°€ì§€ ì•Œê³ ë¦¬ì¦˜ êµ¬í˜„ ë° ë¹„êµ.

---

## ðŸ› ï¸ ì„¤ì¹˜ ë° ìš”êµ¬ì‚¬í•­ (Installation)

ì´ í”„ë¡œì íŠ¸ëŠ” Python 3.8+ í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ëŠ” ê²ƒì„ ê¶Œìž¥í•©ë‹ˆë‹¤.

```bash
# ì €ìž¥ì†Œ í´ë¡ 
git clone [https://github.com/YourUsername/Your-Repo-Name.git](https://github.com/YourUsername/Your-Repo-Name.git)
cd Your-Repo-Name

# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
pip install numpy torch matplotlib pandas pygame
````

-----

## ðŸš€ ì‹¤í–‰ ë°©ë²• (Usage)

### 1\. ì•Œê³ ë¦¬ì¦˜ í›ˆë ¨ (Training)

ì§€ì •ëœ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ í›ˆë ¨ì„ ì‹œìž‘í•©ë‹ˆë‹¤. (ê¸°ë³¸ 2000 ì—í”¼ì†Œë“œ)

```bash
# ê¸°ë³¸ PPO í›ˆë ¨
python project.py --algo ppo --mode train

# ë³€í˜• ëª¨ë¸ í›ˆë ¨ (rppo, hppo, cppo ì¤‘ ì„ íƒ)
python project.py --algo cppo --mode train
```

  * `--openness`: ë¯¸ë¡œì˜ ê°œë°©ë„ ì„¤ì • (ê¸°ë³¸ 0.6, 0.0\~1.0)
  * `--render`: í•™ìŠµ ê³¼ì •ì„ ì‹œê°í™”í•˜ì—¬ í™•ì¸ (í•™ìŠµ ì†ë„ê°€ ëŠë ¤ì§ˆ ìˆ˜ ìžˆìŒ)

### 2\. ìˆœì°¨ì  ì „ì²´ ì‹¤í—˜ (Run All Experiments)

ëª¨ë“  ì•Œê³ ë¦¬ì¦˜(PPO -\> H-PPO -\> R-PPO -\> C-PPO)ì„ ìˆœì°¨ì ìœ¼ë¡œ í›ˆë ¨í•©ë‹ˆë‹¤.

```bash
python project.py --algo all
```

### 3\. í…ŒìŠ¤íŠ¸ ë° ì‹œê°í™” (Testing)

í›ˆë ¨ëœ ëª¨ë¸(`saved_models/`)ì„ ë¶ˆëŸ¬ì™€ ì„±ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ê³  ì£¼í–‰ í™”ë©´ì„ ë Œë”ë§í•©ë‹ˆë‹¤.

```bash
python project.py --algo cppo --mode test --render
```

### 4\. ê²°ê³¼ ê·¸ëž˜í”„ ê·¸ë¦¬ê¸° (Plotting)

`logs/` í´ë”ì— ì €ìž¥ëœ í•™ìŠµ ë¡œê·¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì„±ëŠ¥ ë¹„êµ ê·¸ëž˜í”„ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

```bash
python plot_results.py
```

> ì‹¤í–‰ í›„ `plots/` í´ë”ì— ê²°ê³¼ ì´ë¯¸ì§€ê°€ ì €ìž¥ë©ë‹ˆë‹¤.

-----

## ðŸ§  ì•Œê³ ë¦¬ì¦˜ ë° ëª¨ë¸ êµ¬ì¡° (Algorithms)

| ì•Œê³ ë¦¬ì¦˜ | ì„¤ëª… | íŠ¹ì§• |
| :--- | :--- | :--- |
| **PPO** | Standard MLP | í˜„ìž¬ ì‹œì ì˜ ì„¼ì„œ ë°ì´í„°(38ì°¨ì›)ë§Œ ì‚¬ìš©í•˜ëŠ” Baseline ëª¨ë¸. |
| **H-PPO** | History Stacking | ê³¼ê±° 3ê°œì˜ í”„ë ˆìž„ì„ ì—°ê²°(Concat)í•˜ì—¬ ìž…ë ¥. ë‹¨ê¸° ì†ë„/ê°€ì†ë„ ì •ë³´ íŒŒì•…. |
| **R-PPO** | Recurrent (GRU) | GRU ì…€ì„ ë„ìž…í•˜ì—¬ ê¸´ ì‹œê³„ì—´ ë°ì´í„°(Context)ë¥¼ ê¸°ì–µ. |
| **C-PPO** | 1D CNN | 1D Convolutionì„ ì‚¬ìš©í•˜ì—¬ ì‹œê³„ì—´ ë°ì´í„°ì—ì„œ ì‹œê³µê°„ì  íŠ¹ì§• ì¶”ì¶œ. |

-----

## ðŸŒ í™˜ê²½ êµ¬ì„± (Environment Detail)

### State Space (38-dim)

  * **LiDAR**: 36ê°œì˜ Ray-casting ê±°ë¦¬ ì •ë³´ (0.0 \~ 1.0 ì •ê·œí™”)
  * **Previous Action**: ì´ì „ ìŠ¤í…ì˜ ì„ ì†ë„, ê°ì†ë„ (ê´€ì„± ë°˜ì˜)

### Action Space (Continuous)

  * **Linear Velocity**: ì „ì§„ ì†ë„ (-1.0 \~ 1.0)
  * **Angular Velocity**: íšŒì „ ì†ë„ (-1.0 \~ 1.0)

### Reward System

  * **Coverage (+)**: ìƒˆë¡­ê²Œ ë°í˜€ì§„ ê·¸ë¦¬ë“œ ì…€ ìˆ˜ì— ë¹„ë¡€.
  * **Frontier (+)**: ë¯¸íƒì‚¬ êµ¬ì—­ì— ê°€ê¹Œì›Œì§ˆìˆ˜ë¡ ë³´ìƒ ë¶€ì—¬.
  * **Penalty (-)**: ì¶©ëŒ, ì œìžë¦¬ íšŒì „, ì‹œê°„ ê²½ê³¼ì— ëŒ€í•œ íŽ˜ë„í‹°.

-----

## ðŸ“Š ì‹¤í—˜ ê²°ê³¼ (Experimental Results)

ì´ 2000 ì—í”¼ì†Œë“œ í•™ìŠµ ê²°ê³¼, \*\*ë©”ëª¨ë¦¬ ê¸°ëŠ¥ì´ ìžˆëŠ” ëª¨ë¸(C-PPO, R-PPO)\*\*ì´ ìš°ìˆ˜í•œ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

### 1\. íƒìƒ‰ íš¨ìœ¨ì„± (Coverage)

  * **C-PPO**ì™€ **R-PPO**ëŠ” ì•½ 250 ì—í”¼ì†Œë“œ ë§Œì— 80% ì´ìƒì˜ Coverageì— ë„ë‹¬í•˜ë©° ê°€ìž¥ ë¹ ë¥¸ ìˆ˜ë ´ ì†ë„ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.
  * **H-PPO**ëŠ” ì°¨ì›ì˜ ì €ì£¼ë¡œ ì¸í•´ ì´ˆê¸° í•™ìŠµì´ ì§€ì—°ë˜ëŠ” í˜„ìƒì„ ë³´ì˜€ìŠµë‹ˆë‹¤.

### 2\. ì£¼í–‰ ì•ˆì •ì„± (Return)

  * **C-PPO**ê°€ ê°€ìž¥ ë†’ì€ í‰ê·  ë³´ìƒì„ ê¸°ë¡í•˜ë©°, ë¶ˆí•„ìš”í•œ íšŒì „ì´ë‚˜ ì¶©ëŒ ì—†ëŠ” íš¨ìœ¨ì ì¸ ì£¼í–‰ ì •ì±…ì„ í•™ìŠµí–ˆìŒì„ ìž…ì¦í–ˆìŠµë‹ˆë‹¤.

-----

## âš™ï¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° (Hyperparameters)

| Parameter | PPO / H-PPO / R-PPO | C-PPO |
| :--- | :---: | :---: |
| **Learning Rate** | 3e-4 | **1e-4** |
| **Batch Size** | 64 | **512** |
| **Update Interval** | 2048 | **4096** |
| **Gamma** | 0.99 | 0.99 |
| **Entropy Coef** | 0.01 | **0.025** |

-----

## ðŸ‘¥ íŒ€ì› (Team)

  * **ë‚¨ê·œë²”**: 3D PyBullet í™˜ê²½ êµ¬ì¶• ë° ë¹„êµ ì‹¤í—˜
  * **í•¨í˜•ì›**: 2D ì‹œë®¬ë ˆì´ì…˜ í™˜ê²½ êµ¬ì¶• ë° ì•Œê³ ë¦¬ì¦˜(PPO variants) êµ¬í˜„

-----

## ðŸ“ License

This project is licensed under the MIT License.

```

### ì¶”ê°€ íŒ
* `plots/coverage_comparison.png` ì™€ ê°™ì€ ì´ë¯¸ì§€ ê²½ë¡œê°€ ì‹¤ì œ íŒŒì¼ ìœ„ì¹˜ì™€ ë§žëŠ”ì§€ í™•ì¸ í›„ ì—…ë¡œë“œí•˜ì„¸ìš”.
* `requirements.txt` íŒŒì¼ì„ ë§Œë“¤ì–´ í•¨ê»˜ ì˜¬ë¦¬ë©´ ì‚¬ìš©ìžë“¤ì´ ë” íŽ¸í•˜ê²Œ ì„¤ì¹˜í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤. (`pip freeze > requirements.txt`)
```